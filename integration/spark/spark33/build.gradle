plugins {
    id 'java-library'
    id 'com.diffplug.spotless' version '6.12.0'
    id "com.adarshr.test-logger" version "3.2.0"
    id "org.gradle.test-retry" version "1.5.8"
    id "pmd"
}

pmd {
    consoleOutput = true
    toolVersion = "6.46.0"
    rulesMinimumPriority = 5
    ruleSetFiles = rootProject.files("pmd-openlineage.xml")
    ruleSets = []
    ignoreFailures = true
}

pmdMain {
    reports {
        html.required = true
    }
}

repositories {
    mavenLocal()
    mavenCentral()
    maven {
        url = 'https://astronomer.jfrog.io/artifactory/maven-public-libs-snapshot'
    }
}

archivesBaseName = 'openlineage-spark-spark3'

ext {
    assertjVersion = '3.25.1'
    junit5Version = '5.10.1'
    mockitoVersion = '4.11.0'
    sparkVersion = '3.3.3'
    scalaVersion = project.getProperty('scala.binary.version')
    jacksonVersion = '2.15.3'
    lombokVersion = '1.18.30'
    icebergVersion = '0.14.1'
}

configurations.configureEach {
    // https://github.com/apache/spark/pull/38355 - can be remove for Spark 3.3.2
    resolutionStrategy {
        // https://github.com/FasterXML/jackson-databind/issues/3627
        force "com.fasterxml.jackson:jackson-bom:$jacksonVersion"
    }
}

sourceSets {
    scala213 {
        java {
            srcDir("src/main/java")
        }
        resources {
            srcDir("src/main/resources")
        }
    }

    scala213Test {
        java {
            srcDir("src/test/java")
            compileClasspath += sourceSets.scala213.output + sourceSets.scala213.compileClasspath
            runtimeClasspath += sourceSets.scala213.output + sourceSets.scala213.runtimeClasspath
        }
        resources {
            srcDir("src/test/resources")
        }
    }
}

dependencies {
    compileOnly "org.projectlombok:lombok:${lombokVersion}"
    annotationProcessor "org.projectlombok:lombok:${lombokVersion}"
    testCompileOnly "org.projectlombok:lombok:${lombokVersion}"
    testAnnotationProcessor "org.projectlombok:lombok:${lombokVersion}"

    implementation(project(path: ":shared"))
    implementation(project(path: ":spark3"))
    implementation("org.apache.spark:spark-core_2.12:${sparkVersion}")
    implementation("org.apache.spark:spark-sql_2.12:${sparkVersion}")
    implementation("org.apache.spark:spark-hive_2.12:${sparkVersion}")
    implementation("org.apache.spark:spark-sql-kafka-0-10_2.12:${sparkVersion}")
    implementation("org.apache.iceberg:iceberg-spark-runtime-3.3_2.12:${icebergVersion}")

    testImplementation("org.junit.jupiter:junit-jupiter:${junit5Version}")
    testImplementation("org.assertj:assertj-core:${assertjVersion}")
    testImplementation("org.mockito:mockito-core:${mockitoVersion}")
    testImplementation("org.mockito:mockito-inline:${mockitoVersion}")
    testImplementation("org.junit.jupiter:junit-jupiter-api:${junit5Version}")

    scala213Implementation(project(path: ':shared'))
    scala213Implementation(project(path: ':spark3'))
    scala213Implementation("org.projectlombok:lombok:${lombokVersion}")
    scala213Implementation("org.apache.spark:spark-core_2.13:${sparkVersion}")
    scala213Implementation("org.apache.spark:spark-sql_2.13:${sparkVersion}")
    scala213Implementation("org.apache.spark:spark-hive_2.13:${sparkVersion}")
    scala213Implementation("org.apache.spark:spark-sql-kafka-0-10_2.13:${sparkVersion}")
    scala213Implementation("org.apache.iceberg:iceberg-spark-runtime-3.3_2.13:${icebergVersion}")

    scala213TestImplementation("org.junit.jupiter:junit-jupiter:${junit5Version}")
    scala213TestImplementation("org.assertj:assertj-core:${assertjVersion}")
    scala213TestImplementation("org.mockito:mockito-core:${mockitoVersion}")
    scala213TestImplementation("org.mockito:mockito-inline:${mockitoVersion}")
    scala213TestImplementation("org.junit.jupiter:junit-jupiter-api:${junit5Version}")
}

def commonTestConfiguration = {
    forkEvery 1
    maxParallelForks 5
    testLogging {
        events "passed", "skipped", "failed"
        showStandardStreams = true
    }
    systemProperties = [
            'junit.platform.output.capture.stdout': 'true',
            'junit.platform.output.capture.stderr': 'true',
            'spark.version'                       : "${sparkVersion}",
            'openlineage.spark.jar'               : "${archivesBaseName}-${project.version}.jar",
            'kafka.package.version'               : "org.apache.spark:spark-sql-kafka-0-10_2.12:${sparkVersion}",
            'mockserver.logLevel'                 : 'ERROR'
    ]
}

tasks.withType(Test).configureEach {
    configure commonTestConfiguration
    useJUnitPlatform()
}

tasks.register("testScala213Test", Test) {
    description = "Runs unit tests using the Apache Spark 3.3.x libraries compiled with Scala 2.13.y"
    group = "verification"
    testClassesDirs = sourceSets.scala213Test.output.classesDirs
    classpath = sourceSets.scala213Test.runtimeClasspath
}

tasks.withType(JavaCompile).configureEach {
    // add annotation processor classpath to each java compile task
    options.annotationProcessorPath = configurations.annotationProcessor
}

tasks.register("testAll") {
    dependsOn(tasks.named("test"), tasks.named("testScala213Test"))
    description = "Runs all unit tests"
    group = "verification"
}

tasks.build {
    dependsOn(tasks.named("testAll"))
}

spotless {
    def disallowWildcardImports = {
        String text = it
        def regex = ~/import .*\.\*;/
        def m = regex.matcher(text)
        if (m.find()) {
            throw new AssertionError("Wildcard imports disallowed - ${m.findAll()}")
        }
    }
    java {
        googleJavaFormat()
        removeUnusedImports()
        custom 'disallowWildcardImports', disallowWildcardImports
    }
}

task printSourceSetInformation {
    doLast {
        sourceSets.each { srcSet ->
            println "[" + srcSet.name + "]"
            print "-->Source directories: " + srcSet.allJava.srcDirs + "\n"
            print "-->Output directories: " + srcSet.output.classesDirs.files + "\n"
            print "-->Compile classpath:\n"
            srcSet.compileClasspath.files.each {
                print "  " + it.path + "\n"
            }
            println ""
        }
    }
}
