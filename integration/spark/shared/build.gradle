plugins {
    id("io.openlineage.common-java-config")
    id("io.openlineage.print-source-set-configuration")
    id("io.openlineage.scala213-variant")
    id("io.openlineage.standard-spotless")
    id("io.freefair.lombok") version "8.4"
}

lombok {
    version = "1.18.30"
}

ext {
    assertjVersion = "3.25.1"
    bigqueryVersion = "0.29.0"
    junit5Version = "5.10.1"
    snowflakeVersion = "2.11.0"
    postgresqlVersion = "42.7.1"
    mockitoVersion = "4.11.0"
    testcontainersVersion = "1.19.3"

    // What's going here?
    // This two properties control which versions of Spark and Scala are used to write the code.
    // This controls the packages that your IDE, like IntelliJ, will use to provide code completion.
    // Why do we need this? Because the API of Apache Spark evolves over time, and keeping the
    // versions unchanging will show us that sometimes the code we write isn't compatible with differing
    // versions of Spark.
    defaultSparkVersion = project.findProperty('shared.default.spark.version') ?: "3.2.4"
    defaultSparkSeries = defaultSparkVersion.substring(0, 3)
    defaultScalaVersion = project.findProperty('shared.default.scala.version') ?: "2.12"

    scala212SparkVersion = "3.2.4"
    scala212SparkSeries = scala212SparkVersion.substring(0, 3)

    scala213SparkVersion = "3.2.4"
    scala213SparkSeries = scala213SparkVersion.substring(0, 3)
}

dependencies {
    api("io.openlineage:openlineage-java:${project.version}")
    api("io.openlineage:openlineage-sql-java:${project.version}")

    compileOnly("org.apache.spark:spark-core_${defaultScalaVersion}:${defaultSparkVersion}")
    compileOnly("org.apache.spark:spark-sql_${defaultScalaVersion}:${defaultSparkVersion}")
    compileOnly("com.google.cloud.spark:spark-bigquery-with-dependencies_${defaultScalaVersion}:${bigqueryVersion}") {
        exclude group: "com.fasterxml.jackson.core"
        exclude group: "com.fasterxml.jackson.module"
    }
    compileOnly("net.snowflake:spark-snowflake_${defaultScalaVersion}:${snowflakeVersion}-spark_${defaultSparkSeries}") {
        exclude group: "com.google.guava:guava"
        exclude group: "org.apache.spark:spark-core_${defaultScalaVersion}"
        exclude group: "org.apache.spark:spark-sql_${defaultScalaVersion}"
        exclude group: "org.apache.spark:spark-catalyst_${defaultScalaVersion}"
    }

    compileOnly("org.apache.spark:spark-hive_${defaultScalaVersion}:${defaultSparkVersion}")
    compileOnly("org.apache.spark:spark-sql-kafka-0-10_${defaultScalaVersion}:${defaultSparkVersion}")
    compileOnly("com.databricks:databricks-dbutils-scala_${defaultScalaVersion}:0.1.4") {
        exclude group: "com.fasterxml.jackson.core"
    }

    testImplementation(platform("org.junit:junit-bom:${junit5Version}"))
    testImplementation("org.junit.jupiter:junit-jupiter")
    testImplementation("org.junit.jupiter:junit-jupiter-params")

    testImplementation("org.postgresql:postgresql:${postgresqlVersion}")
    testImplementation("org.xerial:sqlite-jdbc:3.44.1.0")
    testImplementation("org.apache.kafka:kafka-clients:3.6.1")
    testImplementation("org.mock-server:mockserver-client-java:5.14.0") {
        exclude group: "com.google.guava", module: "guava"
        exclude group: "com.fasterxml.jackson.core"
        exclude group: "com.fasterxml.jackson.datatype"
        exclude group: "com.fasterxml.jackson.dataformat"
    }
    testImplementation("org.awaitility:awaitility:4.2.0")
    testImplementation("org.assertj:assertj-core:${assertjVersion}")
    testImplementation("org.mockito:mockito-core:${mockitoVersion}")
    testImplementation("org.mockito:mockito-inline:${mockitoVersion}")
    testImplementation("org.mockito:mockito-junit-jupiter:${mockitoVersion}")
    testImplementation("org.apache.spark:spark-core_${defaultScalaVersion}:${defaultSparkVersion}")
    testImplementation("org.apache.spark:spark-sql_${defaultScalaVersion}:${defaultSparkVersion}")
    testImplementation("org.apache.spark:spark-hive_${defaultScalaVersion}:${defaultSparkVersion}")
    testImplementation("com.google.cloud.spark:spark-bigquery-with-dependencies_${defaultScalaVersion}:${bigqueryVersion}")

    scala213Api("io.openlineage:openlineage-java:${project.version}")
    scala213Api("io.openlineage:openlineage-sql-java:${project.version}")

    scala213CompileOnly("org.apache.spark:spark-core_2.13:${scala213SparkVersion}")
    scala213CompileOnly("org.apache.spark:spark-sql_2.13:${scala213SparkVersion}")
    scala213CompileOnly("org.apache.spark:spark-hive_2.13:${scala213SparkVersion}")
    scala213CompileOnly("org.apache.spark:spark-sql-kafka-0-10_2.13:${scala213SparkVersion}")

    scala213CompileOnly("com.google.cloud.spark:spark-bigquery-with-dependencies_2.13:${bigqueryVersion}") {
        exclude group: "com.fasterxml.jackson.core"
        exclude group: "com.fasterxml.jackson.module"
    }

    scala213CompileOnly("net.snowflake:spark-snowflake_2.13:${snowflakeVersion}-spark_${scala213SparkSeries}") {
        exclude group: "com.google.guava:guava"
        exclude group: "org.apache.spark:spark-core_2.13"
        exclude group: "org.apache.spark:spark-sql_2.13"
        exclude group: "org.apache.spark:spark-catalyst_2.13"
    }

    scala213CompileOnly("com.databricks:databricks-dbutils-scala_2.13:0.1.4") {
        exclude group: "com.fasterxml.jackson.core"
    }

    testScala213Implementation("org.assertj:assertj-core:${assertjVersion}")
    testScala213Implementation("org.awaitility:awaitility:4.2.0")
    testScala213Implementation(platform("org.junit:junit-bom:${junit5Version}"))
    testScala213Implementation("org.junit.jupiter:junit-jupiter")
    testScala213Implementation("org.junit.jupiter:junit-jupiter-api")
    testScala213Implementation("org.mockito:mockito-core:${mockitoVersion}")
    testScala213Implementation("org.mockito:mockito-inline:${mockitoVersion}")
    testScala213Implementation("org.postgresql:postgresql:${postgresqlVersion}")
    testScala213Implementation("org.apache.spark:spark-core_2.13:${scala213SparkVersion}")
    testScala213Implementation("org.apache.spark:spark-sql_2.13:${scala213SparkVersion}")
    testScala213Implementation("org.apache.spark:spark-hive_2.13:${scala213SparkVersion}")
    testScala213Implementation("com.google.cloud.spark:spark-bigquery-with-dependencies_2.13:${bigqueryVersion}")
}

tasks.withType(Test).configureEach {
    // TODO: This should be removed. This is set because there is a single test that fails - namely the bigquery
    //  logical plan serialisation test.
    ignoreFailures = true
}
